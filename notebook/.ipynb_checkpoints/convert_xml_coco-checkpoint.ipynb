{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import json\n",
    "import shutil\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding:utf-8\n",
    "# 运行前请先做以下工作：\n",
    "# pip install lxml\n",
    "# 将所有的图片及xml文件存放到xml_dir指定的文件夹下，并将此文件夹放置到当前目录下\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "START_BOUNDING_BOX_ID = 1\n",
    "save_path = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get(root, name):\n",
    "    return root.findall(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_check(root, name, length):\n",
    "    vars = get(root, name)\n",
    "    if len(vars) == 0:\n",
    "        raise NotImplementedError('Can not find %s in %s.' % (name, root.tag))\n",
    "    if length and len(vars) != length:\n",
    "        raise NotImplementedError('The size of %s is supposed to be %d, but is %d.' % (name, length, len(vars)))\n",
    "    if length == 1:\n",
    "        vars = vars[0]\n",
    "    return vars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(xml_list, json_file):\n",
    "    json_dict = {\"images\": [], \"type\": \"instances\", \"annotations\": [], \"categories\": []}\n",
    "    categories = pre_define_categories.copy()\n",
    "    bnd_id = START_BOUNDING_BOX_ID\n",
    "    all_categories = {}\n",
    "    for index, line in enumerate(xml_list):\n",
    "        # print(\"Processing %s\"%(line))\n",
    "        xml_f = line\n",
    "        tree = ET.parse(xml_f)\n",
    "        root = tree.getroot()\n",
    "\n",
    "        filename = os.path.basename(xml_f)[:-4] + \".jpg\"\n",
    "        image_id = 20190000001 + index\n",
    "        size = get_and_check(root, 'size', 1)\n",
    "        width = int(get_and_check(size, 'width', 1).text)\n",
    "        height = int(get_and_check(size, 'height', 1).text)\n",
    "        image = {'file_name': filename, 'height': height, 'width': width, 'id': image_id}\n",
    "        json_dict['images'].append(image)\n",
    "        #  Currently we do not support segmentation\n",
    "        segmented = get_and_check(root, 'segmented', 1).text\n",
    "        assert segmented == '0'\n",
    "        for obj in get(root, 'object'):\n",
    "            category = get_and_check(obj, 'name', 1).text\n",
    "            if category in all_categories:\n",
    "                all_categories[category] += 1\n",
    "            else:\n",
    "                all_categories[category] = 1\n",
    "            if category not in categories:\n",
    "                if only_care_pre_define_categories:\n",
    "                    continue\n",
    "                new_id = len(categories) + 1\n",
    "                print(\n",
    "                    \"[warning] category '{}' not in 'pre_define_categories'({}), create new id: {} automatically\".format(\n",
    "                        category, pre_define_categories, new_id))\n",
    "                categories[category] = new_id\n",
    "            category_id = categories[category]\n",
    "            bndbox = get_and_check(obj, 'bndbox', 1)\n",
    "            xmin = int(float(get_and_check(bndbox, 'xmin', 1).text))\n",
    "            ymin = int(float(get_and_check(bndbox, 'ymin', 1).text))\n",
    "            xmax = int(float(get_and_check(bndbox, 'xmax', 1).text))\n",
    "            ymax = int(float(get_and_check(bndbox, 'ymax', 1).text))\n",
    "            assert (xmax > xmin), \"xmax <= xmin, {}\".format(line)\n",
    "            assert (ymax > ymin), \"ymax <= ymin, {}\".format(line)\n",
    "            o_width = abs(xmax - xmin)\n",
    "            o_height = abs(ymax - ymin)\n",
    "            ann = {'area': o_width * o_height, 'iscrowd': 0, 'image_id':\n",
    "                image_id, 'bbox': [xmin, ymin, o_width, o_height],\n",
    "                   'category_id': category_id, 'id': bnd_id, 'ignore': 0,\n",
    "                   'segmentation': []}\n",
    "            json_dict['annotations'].append(ann)\n",
    "            bnd_id = bnd_id + 1\n",
    "\n",
    "    for cate, cid in categories.items():\n",
    "        cat = {'supercategory': 'food', 'id': cid, 'name': cate}\n",
    "        json_dict['categories'].append(cat)\n",
    "    json_fp = open(json_file, 'w')\n",
    "    json_str = json.dumps(json_dict)\n",
    "    json_fp.write(json_str)\n",
    "    json_fp.close()\n",
    "    print(\"------------create {} done--------------\".format(json_file))\n",
    "    print(\"find {} categories: {} -->>> your pre_define_categories {}: {}\".format(len(all_categories),\n",
    "                                                                                  all_categories.keys(),\n",
    "                                                                                  len(pre_define_categories),\n",
    "                                                                                  pre_define_categories.keys()))\n",
    "    print(\"category: id --> {}\".format(categories))\n",
    "    print(categories.keys())\n",
    "    print(categories.values())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------create /data1/wjb/Centernet_mod/data/ADC/annotations/train_adc.json done--------------\n",
      "find 1 categories: dict_keys(['others']) -->>> your pre_define_categories 1: dict_keys(['others'])\n",
      "category: id --> {'others': 1}\n",
      "dict_keys(['others'])\n",
      "dict_values([1])\n",
      "------------create /data1/wjb/Centernet_mod/data/ADC/annotations/val_adc.json done--------------\n",
      "find 1 categories: dict_keys(['others']) -->>> your pre_define_categories 1: dict_keys(['others'])\n",
      "category: id --> {'others': 1}\n",
      "dict_keys(['others'])\n",
      "dict_values([1])\n",
      "------------create /data1/wjb/Centernet_mod/data/ADC/annotations/test_adc.json done--------------\n",
      "find 1 categories: dict_keys(['others']) -->>> your pre_define_categories 1: dict_keys(['others'])\n",
      "category: id --> {'others': 1}\n",
      "dict_keys(['others'])\n",
      "dict_values([1])\n",
      "--------------------------------------------------\n",
      "train number: 5676\n",
      "val number: 709\n",
      "test number: 709\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 定义你自己的类别\n",
    "    classes = ['others']\n",
    "    pre_define_categories = {}\n",
    "    for i, cls in enumerate(classes):\n",
    "        pre_define_categories[cls] = i + 1\n",
    "    # 这里也可以自定义类别id，把上面的注释掉换成下面这行即可\n",
    "    # pre_define_categories = {'a1': 1, 'a3': 2, 'a6': 3, 'a9': 4, \"a10\": 5}\n",
    "    only_care_pre_define_categories = True  # or False\n",
    "\n",
    "    # 保存的json文件\n",
    "    save_json_train = '/data1/wjb/Centernet_mod/data/ADC/annotations/train_adc.json'\n",
    "    save_json_val = '/data1/wjb/Centernet_mod/data/ADC/annotations/val_adc.json'\n",
    "    save_json_test = '/data1/wjb/Centernet_mod/data/ADC/annotations/test_adc.json'\n",
    "\n",
    "    # 初始文件所在的路径\n",
    "    xml_dir = \"/data1/wjb/Centernet_mod/data/ADC/xml\"\n",
    "    xml_list = glob.glob(xml_dir + \"/*.xml\")\n",
    "    xml_list = np.sort(xml_list)\n",
    "\n",
    "    # 打乱数据集\n",
    "    np.random.seed(100)\n",
    "    np.random.shuffle(xml_list)\n",
    "\n",
    "    # 按比例划分打乱后的数据集\n",
    "    train_ratio = 0.8\n",
    "    val_ratio = 0.1\n",
    "    train_num = int(len(xml_list) * train_ratio)\n",
    "    val_num = int(len(xml_list) * val_ratio)\n",
    "    xml_list_train = xml_list[:train_num]\n",
    "    xml_list_val = xml_list[train_num: train_num+val_num]\n",
    "    xml_list_test = xml_list[train_num+val_num:]\n",
    "\n",
    "    # 将xml文件转为coco文件，在指定目录下生成三个json文件（train/test/food）\n",
    "    convert(xml_list_train, save_json_train)\n",
    "    convert(xml_list_val, save_json_val)\n",
    "    convert(xml_list_test, save_json_test)\n",
    "\n",
    "    # # 将图片按照划分后的结果进行存放\n",
    "    # if os.path.exists(save_path + \"/annotations\"):\n",
    "    #     shutil.rmtree(save_path + \"/annotations\")\n",
    "    # os.makedirs(save_path + \"/annotations\")\n",
    "    # if os.path.exists(save_path + \"/images_divide/train\"):\n",
    "    #     shutil.rmtree(save_path + \"/images_divide/train\")\n",
    "    # os.makedirs(save_path + \"/images_divide/train\")\n",
    "    # if os.path.exists(save_path + \"/images_divide/val\"):\n",
    "    #     shutil.rmtree(save_path + \"/images_divide/val\")\n",
    "    # os.makedirs(save_path + \"/images_divide/val\")\n",
    "    # if os.path.exists(save_path + \"/images_divide/test\"):\n",
    "    #     shutil.rmtree(save_path + \"/images_divide/test\")\n",
    "    # os.makedirs(save_path + \"/images_divide/test\")\n",
    "\n",
    "    # # 按需执行，生成3个txt文件，存放相应的文件名称\n",
    "    # f1 = open(\"./train.txt\", \"w\")\n",
    "    # for xml in xml_list_train:\n",
    "    #     img = xml[:-4] + \".jpg\"\n",
    "    #     f1.write(os.path.basename(xml)[:-4] + \"\\n\")\n",
    "    #     shutil.copyfile(img, save_path + \"/images_divide/train/\" + os.path.basename(img))\n",
    "    #\n",
    "    # f2 = open(\"val.txt\", \"w\")\n",
    "    # for xml in xml_list_val:\n",
    "    #     img = xml[:-4] + \".jpg\"\n",
    "    #     f2.write(os.path.basename(xml)[:-4] + \"\\n\")\n",
    "    #     shutil.copyfile(img, save_path + \"/images_divide/val/\" + os.path.basename(img))\n",
    "    #\n",
    "    # f3 = open(\"test.txt\", \"w\")\n",
    "    # for xml in xml_list_val:\n",
    "    #     img = xml[:-4] + \".jpg\"\n",
    "    #     f2.write(os.path.basename(xml)[:-4] + \"\\n\")\n",
    "    #     shutil.copyfile(img, save_path + \"/images_divide/test/\" + os.path.basename(img))\n",
    "    #\n",
    "    # f1.close()\n",
    "    # f2.close()\n",
    "    # f3.close()\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"train number:\", len(xml_list_train))\n",
    "    print(\"val number:\", len(xml_list_val))\n",
    "    print(\"test number:\", len(xml_list_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
