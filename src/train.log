nohup: ignoring input
Using tensorboardX
Fix size testing.
training chunk_sizes: [16]
The output will be saved to  /data1/wjb/Centernet_mod/src/lib/../../exp/ctdet/food
heads {'hm': 1, 'wh': 2, 'reg': 2}
Namespace(K=100, aggr_weight=0.0, agnostic_ex=False, arch='dla_34', aug_ddd=0.5, aug_rot=0, batch_size=16, cat_spec_wh=False, center_thresh=0.1, chunk_sizes=[16], data_dir='/data1/wjb/Centernet_mod/src/lib/../../data', dataset='adc', debug=0, debug_dir='/data1/wjb/Centernet_mod/src/lib/../../exp/ctdet/food/debug', debugger_theme='white', demo='', dense_hp=False, dense_wh=False, dep_weight=1, dim_weight=1, down_ratio=4, eval_oracle_dep=False, eval_oracle_hm=False, eval_oracle_hmhp=False, eval_oracle_hp_offset=False, eval_oracle_kps=False, eval_oracle_offset=False, eval_oracle_wh=False, exp_dir='/data1/wjb/Centernet_mod/src/lib/../../exp/ctdet', exp_id='food', fix_res=True, flip=0.5, flip_test=False, gpus=[0], gpus_str='1', head_conv=256, heads={'hm': 1, 'wh': 2, 'reg': 2}, hide_data_time=False, hm_hp=True, hm_hp_weight=1, hm_weight=1, hp_weight=1, input_h=512, input_res=512, input_w=512, keep_res=False, kitti_split='3dop', load_model='', lr=0.000125, lr_step=[90, 120], master_batch_size=16, mean=array([[[0.40789655, 0.44719303, 0.47026116]]], dtype=float32), metric='loss', mse_loss=False, nms=False, no_color_aug=False, norm_wh=False, not_cuda_benchmark=False, not_hm_hp=False, not_prefetch_test=False, not_rand_crop=False, not_reg_bbox=False, not_reg_hp_offset=False, not_reg_offset=False, num_classes=1, num_epochs=140, num_iters=-1, num_stacks=1, num_workers=4, off_weight=1, output_h=128, output_res=128, output_w=128, pad=31, peak_thresh=0.2, print_iter=0, rect_mask=False, reg_bbox=True, reg_hp_offset=True, reg_loss='l1', reg_offset=True, resume=False, root_dir='/data1/wjb/Centernet_mod/src/lib/../..', rot_weight=1, rotate=0, save_all=False, save_dir='/data1/wjb/Centernet_mod/src/lib/../../exp/ctdet/food', scale=0.4, scores_thresh=0.1, seed=317, shift=0.1, std=array([[[0.2886383 , 0.27408165, 0.27809834]]], dtype=float32), task='ctdet', test=False, test_scales=[1.0], trainval=False, val_intervals=5, vis_thresh=0.3, wh_weight=0.1)
Creating model...
opt.task===== ctdet
Setting up data...
==> initializing coco 2017 val data.
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Loaded val 709 samples
==> initializing coco 2017 train data.
loading annotations into memory...
Done (t=0.13s)
creating index...
index created!
Loaded train 5676 samples
train_loader======== <torch.utils.data.dataloader.DataLoader object at 0x7f1cc43975d0>
Starting training...
/opt/conda/lib/python3.7/site-packages/torch/nn/_reduction.py:43: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.
  warnings.warn(warning.format(ret))
Drop LR to 1.25e-05
Drop LR to 1.2500000000000003e-06
